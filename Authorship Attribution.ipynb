{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajit Samudrala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.decomposition import KernelPCA, PCA\n",
    "from keras.layers import GlobalAvgPool1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D, AveragePooling1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_train = '/Users/ajit_samudrala/author_attribution/train'\n",
    "base_dir_test = '/Users/ajit_samudrala/author_attribution/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(base_dir):\n",
    "    \"\"\"\n",
    "    This function reads files from the given base directory and returns a Dataframe with two columns, articles and author.\n",
    "    :param base_dir: str\n",
    "    :return: dataframe\n",
    "    \"\"\"\n",
    "    authors_list = os.listdir(base_dir)\n",
    "    data = []\n",
    "    labels = []\n",
    "    for index, author in enumerate(authors_list):\n",
    "        author_dir = os.path.join(base_dir, author)\n",
    "        author_articles = os.listdir(author_dir)\n",
    "        for i in range(len(author_articles)):\n",
    "            article_file = open(os.path.join(author_dir, author_articles[i]), mode='r')\n",
    "            data.append(article_file.read())\n",
    "            labels.append(author)\n",
    "            article_file.close()\n",
    "    return pd.DataFrame({'articles': data, 'author': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_files(base_dir_train)\n",
    "df_test = read_files(base_dir_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Internet may be overflowing with new techn...</td>\n",
       "      <td>AaronPressman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The U.S. Postal Service announced Wednesday a ...</td>\n",
       "      <td>AaronPressman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elementary school students with access to the ...</td>\n",
       "      <td>AaronPressman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An influential Internet organisation has backe...</td>\n",
       "      <td>AaronPressman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An influential Internet organisation has backe...</td>\n",
       "      <td>AaronPressman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            articles         author\n",
       "0  The Internet may be overflowing with new techn...  AaronPressman\n",
       "1  The U.S. Postal Service announced Wednesday a ...  AaronPressman\n",
       "2  Elementary school students with access to the ...  AaronPressman\n",
       "3  An influential Internet organisation has backe...  AaronPressman\n",
       "4  An influential Internet organisation has backe...  AaronPressman"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S. Senators on Tuesday sharply criticized a ...</td>\n",
       "      <td>AaronPressman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two members of Congress criticised the Federal...</td>\n",
       "      <td>AaronPressman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commuters stuck in traffic on the Leesburg Pik...</td>\n",
       "      <td>AaronPressman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A broad coalition of corporations went to Capi...</td>\n",
       "      <td>AaronPressman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On the Internet, where new products come and g...</td>\n",
       "      <td>AaronPressman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            articles         author\n",
       "0  U.S. Senators on Tuesday sharply criticized a ...  AaronPressman\n",
       "1  Two members of Congress criticised the Federal...  AaronPressman\n",
       "2  Commuters stuck in traffic on the Leesburg Pik...  AaronPressman\n",
       "3  A broad coalition of corporations went to Capi...  AaronPressman\n",
       "4  On the Internet, where new products come and g...  AaronPressman"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19e70215dd8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['author'].value_counts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19e70263400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test['author'].value_counts().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test data are similarly distributed. An article can be attributed to an author based on the topic and content of the article or the author writing style or mix of both. In my basic approach, I will try to solve the problem by leveraging the frequency of words in the article, which represents the topic of an article. For this, I will construct a TF-IDF matrix. I am not going to rely on the default tokenizer provided by the scikit learn; I will create one for myself. The custom tokenizer involved three steps:\n",
    "\n",
    "* Tokenize the article into sentences and sentences into words\n",
    "* Filter the tokens with smaller lengths (assuming smaller words doesn't really say anything about the topic), whether a word is stop word or not, and whether the word is present in the dictionary or not\n",
    "* Stem the words \n",
    "\n",
    "I am also going to construct a raw counts matrix as some models like MultinomialNB often perform better on raw counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    \"\"\"\n",
    "    Below function tokenizes and lemmatizes the texts. It also does some cleaning by removing non dictionary words\n",
    "    This can be used to replace default tokenizer provided by feature extraction api of sklearn.\n",
    "    :param text: str\n",
    "    :return: list\n",
    "    \"\"\"\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "\n",
    "        if re.search(r'[a-zA-Z-]{4,}', token) and token not in stop_words and len(wn.synsets(token)) > 0:\n",
    "            token.strip()\n",
    "            filtered_tokens.append(token)\n",
    "    filtered_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(max_df=0.8, max_features=10000,\n",
    "                            min_df=0.02, use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1, 2))\n",
    "counter_vect = CountVectorizer(max_df=0.8, max_features=10000,\n",
    "                               min_df=0.02, tokenizer=tokenize_and_stem, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vec.fit_transform(df_train['articles'])\n",
    "tfidf_test = tfidf_vec.transform(df_test['articles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_train = counter_vect.fit_transform(df_train['articles'])\n",
    "counter_test = counter_vect.transform(df_test['articles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df_train['target'] = le.fit_transform(df_train['author'])\n",
    "df_test['target'] = le.transform(df_test['author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have the features and target ready, I will start building the models. I will first start with Bernoulli Naive Bayes, which is simple and fast yet powerful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange;\"><b><i>Naive Bayes for Classification</i></b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train,y_test = tfidf_train, tfidf_test, df_train['target'], df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb = BernoulliNB()\n",
    "clf_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of Naive Bayes Classifer is 0.9524\n",
      "Test score of Naive Bayes Classifer is 0.6432\n"
     ]
    }
   ],
   "source": [
    "print(\"Train score of Naive Bayes Classifer is {}\".format(clf_nb.score(X_train,y_train)))\n",
    "print(\"Test score of Naive Bayes Classifer is {}\".format(clf_nb.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a decent baseline considering the fact that data is small with many classes to classify. I will try MultinomialNB which often performs better, as it leverages the numerical properties of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mnb = MultinomialNB()\n",
    "\n",
    "clf_mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of Multinominal Naive Bayes Classifer is 0.8748\n",
      "Test score of Multinominal Naive Bayes Classifer is 0.5996\n"
     ]
    }
   ],
   "source": [
    "print(\"Train score of Multinominal Naive Bayes Classifer is {}\".format(clf_mnb.score(X_train,y_train)))\n",
    "print(\"Test score of Multinominal Naive Bayes Classifer is {}\".format(clf_mnb.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultinomialNB() doesn't often work well on TF-IDF matrix. Hence, I will try raw counts matrix with MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts, X_test_counts = counter_train, counter_test\n",
    "y_train_counts, y_test_counts = df_train['target'], df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mnb = MultinomialNB()\n",
    "clf_mnb.fit(X_train_counts, y_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of Multinominal Naive Bayes Classifer on Raw counts is 0.9432\n",
      "Test score of Multinominal Naive Bayes Classifer on Raw counts is 0.6256\n"
     ]
    }
   ],
   "source": [
    "print(\"Train score of Multinominal Naive Bayes Classifer on Raw counts is {}\".format(\n",
    "    clf_mnb.score(X_train_counts, y_train_counts)))\n",
    "print(\"Test score of Multinominal Naive Bayes Classifer on Raw counts is {}\".format(\n",
    "    clf_mnb.score(X_test_counts, y_test_counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, BernoulliNB is still a champ. I will try to do parameter tuning using Gridsearch. However, throughout the notebook, I will not perform extensive parameter tuning due to my system constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Green;\"><b><i>Parameter Tuning using Gridsearch And Pipeline</i></b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_naive = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "    ('naive', BernoulliNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...ocabulary=None)), ('naive', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_naive.set_params(tfidf__tokenizer=tokenize_and_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'tfidf__min_df': [0.2,0.1, 0.02],\n",
    "    'tfidf__ngram_range':[(1,1),(1,2),(1,3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...ocabulary=None)), ('naive', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)], 'tfidf__min_df': [0.2, 0.1, 0.02]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = GridSearchCV(pipe_naive, param_grid, cv=4,return_train_score=False)\n",
    "search.fit(df_train['articles'],df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score after the Grid Search is 0.6608\n"
     ]
    }
   ],
   "source": [
    "print(\"The best score after the Grid Search is {}\".format(search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training score actually decreased as doing cross validation decreases the training set size of an already relatively small training set. Nonetheless, I will see if it performs any better on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of best estimator on the test dataset is 0.6432\n"
     ]
    }
   ],
   "source": [
    "print(\"The score of best estimator on the test dataset is {}\".format(\n",
    "    search.best_estimator_.score(df_test['articles'], df_test['target'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Blue;\"><b><i>Logistic Regression OVR</i></b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_log = LogisticRegression(C=0.2) #highly regularizing as from the above results models are overfitting\n",
    "clf_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score of Logistic Regression on Tfidf matrix is 0.808\n",
      "Test score of Logistic Regression on Tfidf matrix is 0.5584\n"
     ]
    }
   ],
   "source": [
    "print(\"Train score of Logistic Regression on Tfidf matrix is {}\".format(clf_log.score(X_train,y_train)))\n",
    "print(\"Test score of Logistic Regression on Tfidf matrix is {}\".format(clf_log.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Red;\"><b><i>XGBOOST</i></b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree-based models often don't perform well on the high dimensional data. Therefore, I will try to reduce the dimensions using PCA and see if it helps. My choice of the parameters of XGboost is heavily influenced by the results obtained from the above models. I try to make trees as conservative as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'booster': 'gbtree', 'max_depth': 2, 'objective': 'multi:softmax', 'eta': 0.08, 'gamma': 1.5, \n",
    "          'num_class': 50, 'saubsample': 0.7, 'eval_metric': ['merror', 'mlogloss'], 'colsample_bytree': 0.55, \n",
    "          'tree_method': 'exact', 'lambda': 2, 'min_child_weight': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = xgb.DMatrix(X_train, y_train)\n",
    "test_data = xgb.DMatrix(X_test, y_test)\n",
    "watchlist = [(train_data, 'train_score'), (test_data, 'test_score')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_early_stop = xgb.callback.early_stop(4) #early stopping if the validation accuracy isn't increasing after 4 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test_score-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test_score-mlogloss hasn't improved in 4 rounds.\n",
      "[0]\ttrain_score-merror:0.6024\ttrain_score-mlogloss:3.60672\ttest_score-merror:0.6892\ttest_score-mlogloss:3.67707\n",
      "[1]\ttrain_score-merror:0.4784\ttrain_score-mlogloss:3.3457\ttest_score-merror:0.6488\ttest_score-mlogloss:3.48757\n",
      "[2]\ttrain_score-merror:0.3948\ttrain_score-mlogloss:3.10366\ttest_score-merror:0.5952\ttest_score-mlogloss:3.30939\n",
      "[3]\ttrain_score-merror:0.3532\ttrain_score-mlogloss:2.91073\ttest_score-merror:0.5752\ttest_score-mlogloss:3.17067\n",
      "[4]\ttrain_score-merror:0.3144\ttrain_score-mlogloss:2.75082\ttest_score-merror:0.5592\ttest_score-mlogloss:3.06465\n",
      "[5]\ttrain_score-merror:0.2888\ttrain_score-mlogloss:2.60244\ttest_score-merror:0.5524\ttest_score-mlogloss:2.9596\n",
      "[6]\ttrain_score-merror:0.2712\ttrain_score-mlogloss:2.47083\ttest_score-merror:0.536\ttest_score-mlogloss:2.86041\n",
      "[7]\ttrain_score-merror:0.2568\ttrain_score-mlogloss:2.35046\ttest_score-merror:0.5256\ttest_score-mlogloss:2.77374\n",
      "[8]\ttrain_score-merror:0.2416\ttrain_score-mlogloss:2.24722\ttest_score-merror:0.5164\ttest_score-mlogloss:2.69982\n",
      "[9]\ttrain_score-merror:0.2356\ttrain_score-mlogloss:2.14942\ttest_score-merror:0.5072\ttest_score-mlogloss:2.62685\n",
      "[10]\ttrain_score-merror:0.222\ttrain_score-mlogloss:2.06065\ttest_score-merror:0.5068\ttest_score-mlogloss:2.56226\n",
      "[11]\ttrain_score-merror:0.2132\ttrain_score-mlogloss:1.97751\ttest_score-merror:0.4944\ttest_score-mlogloss:2.49976\n",
      "[12]\ttrain_score-merror:0.2032\ttrain_score-mlogloss:1.90076\ttest_score-merror:0.4884\ttest_score-mlogloss:2.44738\n",
      "[13]\ttrain_score-merror:0.1952\ttrain_score-mlogloss:1.83006\ttest_score-merror:0.488\ttest_score-mlogloss:2.39537\n",
      "[14]\ttrain_score-merror:0.19\ttrain_score-mlogloss:1.7663\ttest_score-merror:0.4824\ttest_score-mlogloss:2.34875\n",
      "[15]\ttrain_score-merror:0.1808\ttrain_score-mlogloss:1.70487\ttest_score-merror:0.4816\ttest_score-mlogloss:2.30904\n",
      "[16]\ttrain_score-merror:0.1768\ttrain_score-mlogloss:1.64711\ttest_score-merror:0.4784\ttest_score-mlogloss:2.26887\n",
      "[17]\ttrain_score-merror:0.172\ttrain_score-mlogloss:1.59406\ttest_score-merror:0.474\ttest_score-mlogloss:2.23377\n",
      "[18]\ttrain_score-merror:0.1676\ttrain_score-mlogloss:1.54324\ttest_score-merror:0.47\ttest_score-mlogloss:2.19981\n",
      "[19]\ttrain_score-merror:0.1592\ttrain_score-mlogloss:1.49487\ttest_score-merror:0.4672\ttest_score-mlogloss:2.16795\n",
      "[20]\ttrain_score-merror:0.1512\ttrain_score-mlogloss:1.44831\ttest_score-merror:0.462\ttest_score-mlogloss:2.13342\n",
      "[21]\ttrain_score-merror:0.1476\ttrain_score-mlogloss:1.40601\ttest_score-merror:0.4656\ttest_score-mlogloss:2.10725\n",
      "[22]\ttrain_score-merror:0.1448\ttrain_score-mlogloss:1.36387\ttest_score-merror:0.4608\ttest_score-mlogloss:2.07949\n",
      "[23]\ttrain_score-merror:0.1436\ttrain_score-mlogloss:1.3242\ttest_score-merror:0.4572\ttest_score-mlogloss:2.05634\n",
      "[24]\ttrain_score-merror:0.1388\ttrain_score-mlogloss:1.28731\ttest_score-merror:0.4588\ttest_score-mlogloss:2.03174\n",
      "[25]\ttrain_score-merror:0.1356\ttrain_score-mlogloss:1.25242\ttest_score-merror:0.456\ttest_score-mlogloss:2.00832\n",
      "[26]\ttrain_score-merror:0.132\ttrain_score-mlogloss:1.2185\ttest_score-merror:0.458\ttest_score-mlogloss:1.98651\n",
      "[27]\ttrain_score-merror:0.1284\ttrain_score-mlogloss:1.18595\ttest_score-merror:0.4572\ttest_score-mlogloss:1.96725\n",
      "[28]\ttrain_score-merror:0.126\ttrain_score-mlogloss:1.15529\ttest_score-merror:0.4564\ttest_score-mlogloss:1.9487\n",
      "[29]\ttrain_score-merror:0.1212\ttrain_score-mlogloss:1.12564\ttest_score-merror:0.4552\ttest_score-mlogloss:1.93072\n",
      "[30]\ttrain_score-merror:0.1208\ttrain_score-mlogloss:1.09787\ttest_score-merror:0.4532\ttest_score-mlogloss:1.91099\n",
      "[31]\ttrain_score-merror:0.1144\ttrain_score-mlogloss:1.07044\ttest_score-merror:0.4544\ttest_score-mlogloss:1.89252\n",
      "[32]\ttrain_score-merror:0.1072\ttrain_score-mlogloss:1.04454\ttest_score-merror:0.4576\ttest_score-mlogloss:1.87752\n",
      "[33]\ttrain_score-merror:0.106\ttrain_score-mlogloss:1.01923\ttest_score-merror:0.4548\ttest_score-mlogloss:1.86163\n",
      "[34]\ttrain_score-merror:0.1032\ttrain_score-mlogloss:0.995286\ttest_score-merror:0.4524\ttest_score-mlogloss:1.84682\n",
      "[35]\ttrain_score-merror:0.0996\ttrain_score-mlogloss:0.972624\ttest_score-merror:0.4516\ttest_score-mlogloss:1.83224\n",
      "[36]\ttrain_score-merror:0.098\ttrain_score-mlogloss:0.950531\ttest_score-merror:0.4512\ttest_score-mlogloss:1.81996\n",
      "[37]\ttrain_score-merror:0.094\ttrain_score-mlogloss:0.928703\ttest_score-merror:0.4452\ttest_score-mlogloss:1.80529\n",
      "[38]\ttrain_score-merror:0.0924\ttrain_score-mlogloss:0.907251\ttest_score-merror:0.4436\ttest_score-mlogloss:1.79288\n",
      "[39]\ttrain_score-merror:0.0924\ttrain_score-mlogloss:0.887348\ttest_score-merror:0.4424\ttest_score-mlogloss:1.7819\n",
      "[40]\ttrain_score-merror:0.09\ttrain_score-mlogloss:0.868506\ttest_score-merror:0.4424\ttest_score-mlogloss:1.76974\n",
      "[41]\ttrain_score-merror:0.086\ttrain_score-mlogloss:0.850203\ttest_score-merror:0.4404\ttest_score-mlogloss:1.75922\n",
      "[42]\ttrain_score-merror:0.0836\ttrain_score-mlogloss:0.832222\ttest_score-merror:0.4388\ttest_score-mlogloss:1.74853\n",
      "[43]\ttrain_score-merror:0.0824\ttrain_score-mlogloss:0.815032\ttest_score-merror:0.4396\ttest_score-mlogloss:1.73742\n",
      "[44]\ttrain_score-merror:0.0772\ttrain_score-mlogloss:0.797917\ttest_score-merror:0.44\ttest_score-mlogloss:1.72763\n",
      "[45]\ttrain_score-merror:0.0764\ttrain_score-mlogloss:0.781246\ttest_score-merror:0.4384\ttest_score-mlogloss:1.71786\n",
      "[46]\ttrain_score-merror:0.0744\ttrain_score-mlogloss:0.7657\ttest_score-merror:0.4388\ttest_score-mlogloss:1.70914\n",
      "[47]\ttrain_score-merror:0.0708\ttrain_score-mlogloss:0.7502\ttest_score-merror:0.4372\ttest_score-mlogloss:1.69952\n",
      "[48]\ttrain_score-merror:0.0688\ttrain_score-mlogloss:0.735265\ttest_score-merror:0.4392\ttest_score-mlogloss:1.69186\n",
      "[49]\ttrain_score-merror:0.068\ttrain_score-mlogloss:0.720622\ttest_score-merror:0.4368\ttest_score-mlogloss:1.68475\n"
     ]
    }
   ],
   "source": [
    "clf_xgb = xgb.train(params, train_data, evals=watchlist, num_boost_round=50, callbacks=[xgb_early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = clf_xgb.predict(train_data)\n",
    "pred_test = clf_xgb.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGboost model on the TF-IDF train matrix is 0.932\n",
      "Accuracy of XGboost model on the TF-IDF test matrix is 0.5632\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of XGboost model on the TF-IDF train matrix is {}\".format(metrics.accuracy_score(pred_train, \n",
    "                                                                                                 y_train)))\n",
    "print(\"Accuracy of XGboost model on the TF-IDF test matrix is {}\".format(metrics.accuracy_score(pred_test, \n",
    "                                                                                                y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = [int(i[1:]) for i, j in sorted(clf_xgb.get_fscore().items(), key=lambda x: x[1])[::-1][:150]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BernoulliNB() still remains the best model. Ofcourse, one can do lot of parameter tuning with Xgboost. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Orange;\"><b><i>Dimensionality Reduction</i></b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, tree based models tends to perform well with less number of dimensions. Hence, using PCA to see if it helps any way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=500)  # selecting only top 500 principal components\n",
    "X_train_pca = pca.fit_transform(tfidf_train.toarray())\n",
    "X_test_pca = pca.transform(tfidf_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = xgb.DMatrix(X_train_pca, y_train)\n",
    "test_data = xgb.DMatrix(X_test_pca, y_test)\n",
    "watchlist = [(train_data, 'train_score'), (test_data, 'test_score')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'booster': 'gbtree', 'max_depth': 3, 'objective': 'multi:softmax', 'eta': 0.08, 'gamma': 1.5, \n",
    "          'num_class': 50, 'saubsample': 0.7, 'eval_metric': ['merror', 'mlogloss'], 'colsample_bytree': 0.8, \n",
    "          'tree_method': 'exact', 'lambda': 2, 'min_child_weight': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain_score-merror:0.5812\ttrain_score-mlogloss:3.61727\ttest_score-merror:0.724\ttest_score-mlogloss:3.72148\n",
      "[1]\ttrain_score-merror:0.4312\ttrain_score-mlogloss:3.36396\ttest_score-merror:0.6632\ttest_score-mlogloss:3.57029\n",
      "[2]\ttrain_score-merror:0.3716\ttrain_score-mlogloss:3.13274\ttest_score-merror:0.6472\ttest_score-mlogloss:3.445\n",
      "[3]\ttrain_score-merror:0.3244\ttrain_score-mlogloss:2.91892\ttest_score-merror:0.6272\ttest_score-mlogloss:3.32938\n",
      "[4]\ttrain_score-merror:0.2816\ttrain_score-mlogloss:2.72845\ttest_score-merror:0.6176\ttest_score-mlogloss:3.22214\n",
      "[5]\ttrain_score-merror:0.2444\ttrain_score-mlogloss:2.56635\ttest_score-merror:0.6076\ttest_score-mlogloss:3.13425\n",
      "[6]\ttrain_score-merror:0.2172\ttrain_score-mlogloss:2.42279\ttest_score-merror:0.6028\ttest_score-mlogloss:3.05821\n",
      "[7]\ttrain_score-merror:0.1976\ttrain_score-mlogloss:2.29031\ttest_score-merror:0.5952\ttest_score-mlogloss:2.98636\n",
      "[8]\ttrain_score-merror:0.1876\ttrain_score-mlogloss:2.1694\ttest_score-merror:0.582\ttest_score-mlogloss:2.91448\n",
      "[9]\ttrain_score-merror:0.1744\ttrain_score-mlogloss:2.05891\ttest_score-merror:0.5704\ttest_score-mlogloss:2.8568\n",
      "[10]\ttrain_score-merror:0.1636\ttrain_score-mlogloss:1.95878\ttest_score-merror:0.572\ttest_score-mlogloss:2.8029\n",
      "[11]\ttrain_score-merror:0.1556\ttrain_score-mlogloss:1.86801\ttest_score-merror:0.5704\ttest_score-mlogloss:2.75578\n",
      "[12]\ttrain_score-merror:0.1452\ttrain_score-mlogloss:1.78333\ttest_score-merror:0.5656\ttest_score-mlogloss:2.7094\n",
      "[13]\ttrain_score-merror:0.134\ttrain_score-mlogloss:1.70512\ttest_score-merror:0.562\ttest_score-mlogloss:2.66629\n",
      "[14]\ttrain_score-merror:0.1264\ttrain_score-mlogloss:1.63106\ttest_score-merror:0.5584\ttest_score-mlogloss:2.62486\n",
      "[15]\ttrain_score-merror:0.12\ttrain_score-mlogloss:1.56267\ttest_score-merror:0.5532\ttest_score-mlogloss:2.58667\n",
      "[16]\ttrain_score-merror:0.1124\ttrain_score-mlogloss:1.49663\ttest_score-merror:0.5476\ttest_score-mlogloss:2.54829\n",
      "[17]\ttrain_score-merror:0.1092\ttrain_score-mlogloss:1.43517\ttest_score-merror:0.5444\ttest_score-mlogloss:2.51451\n",
      "[18]\ttrain_score-merror:0.1008\ttrain_score-mlogloss:1.37906\ttest_score-merror:0.5384\ttest_score-mlogloss:2.48028\n",
      "[19]\ttrain_score-merror:0.0964\ttrain_score-mlogloss:1.32437\ttest_score-merror:0.534\ttest_score-mlogloss:2.44834\n",
      "[20]\ttrain_score-merror:0.092\ttrain_score-mlogloss:1.27449\ttest_score-merror:0.5352\ttest_score-mlogloss:2.41973\n",
      "[21]\ttrain_score-merror:0.0864\ttrain_score-mlogloss:1.22626\ttest_score-merror:0.5316\ttest_score-mlogloss:2.39372\n",
      "[22]\ttrain_score-merror:0.0816\ttrain_score-mlogloss:1.1809\ttest_score-merror:0.53\ttest_score-mlogloss:2.36747\n",
      "[23]\ttrain_score-merror:0.0788\ttrain_score-mlogloss:1.13924\ttest_score-merror:0.528\ttest_score-mlogloss:2.343\n",
      "[24]\ttrain_score-merror:0.0748\ttrain_score-mlogloss:1.09901\ttest_score-merror:0.5276\ttest_score-mlogloss:2.32066\n",
      "[25]\ttrain_score-merror:0.0684\ttrain_score-mlogloss:1.06055\ttest_score-merror:0.5236\ttest_score-mlogloss:2.29773\n",
      "[26]\ttrain_score-merror:0.0628\ttrain_score-mlogloss:1.02342\ttest_score-merror:0.5228\ttest_score-mlogloss:2.27718\n",
      "[27]\ttrain_score-merror:0.0608\ttrain_score-mlogloss:0.987974\ttest_score-merror:0.5184\ttest_score-mlogloss:2.25691\n",
      "[28]\ttrain_score-merror:0.056\ttrain_score-mlogloss:0.95456\ttest_score-merror:0.5188\ttest_score-mlogloss:2.23691\n",
      "[29]\ttrain_score-merror:0.0536\ttrain_score-mlogloss:0.921991\ttest_score-merror:0.5176\ttest_score-mlogloss:2.21888\n",
      "[30]\ttrain_score-merror:0.0484\ttrain_score-mlogloss:0.892379\ttest_score-merror:0.5148\ttest_score-mlogloss:2.20128\n",
      "[31]\ttrain_score-merror:0.0472\ttrain_score-mlogloss:0.862868\ttest_score-merror:0.5108\ttest_score-mlogloss:2.1842\n",
      "[32]\ttrain_score-merror:0.0444\ttrain_score-mlogloss:0.833539\ttest_score-merror:0.5108\ttest_score-mlogloss:2.16835\n",
      "[33]\ttrain_score-merror:0.0408\ttrain_score-mlogloss:0.806863\ttest_score-merror:0.5104\ttest_score-mlogloss:2.15204\n",
      "[34]\ttrain_score-merror:0.0384\ttrain_score-mlogloss:0.780684\ttest_score-merror:0.5072\ttest_score-mlogloss:2.1389\n",
      "[35]\ttrain_score-merror:0.0368\ttrain_score-mlogloss:0.755414\ttest_score-merror:0.508\ttest_score-mlogloss:2.1248\n",
      "[36]\ttrain_score-merror:0.0356\ttrain_score-mlogloss:0.731452\ttest_score-merror:0.5068\ttest_score-mlogloss:2.11047\n",
      "[37]\ttrain_score-merror:0.0344\ttrain_score-mlogloss:0.708295\ttest_score-merror:0.5036\ttest_score-mlogloss:2.09736\n",
      "[38]\ttrain_score-merror:0.0328\ttrain_score-mlogloss:0.686526\ttest_score-merror:0.5048\ttest_score-mlogloss:2.08429\n",
      "[39]\ttrain_score-merror:0.0296\ttrain_score-mlogloss:0.665662\ttest_score-merror:0.5056\ttest_score-mlogloss:2.07137\n"
     ]
    }
   ],
   "source": [
    "clf_xgb = xgb.train(params, train_data, evals=watchlist, num_boost_round=40, callbacks=[xgb_early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = clf_xgb.predict(train_data)\n",
    "pred_test = clf_xgb.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGboost model on the  reduced TF-IDF train matrix is 0.9704\n",
      "Accuracy of XGboost model on the reduced TF-IDF test matrix is 0.4944\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of XGboost model on the  reduced TF-IDF train matrix is {}\".format(\n",
    "    metrics.accuracy_score(pred_train, y_train)))\n",
    "print(\"Accuracy of XGboost model on the reduced TF-IDF test matrix is {}\".format(\n",
    "    metrics.accuracy_score(pred_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Violet;\"><b><i>Deep Learning</i></b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While above models tried to use the classify the articles based on the words and their frequencies, I will try to build a sequence model that tries to capture the writing style of an author. However, I am dubious about the effectiveness of these models considering the limited amount of data.\n",
    "\n",
    "I will change the tokenizer by removing stem as I am going to replace words with Glove embeddings that provide relevant words vectors to all verb forms of a word. Below are the changes that I will make:\n",
    "\n",
    "* Remove words in the quotes as they don't contribute to capture the writing style of the author.\n",
    "* Not stemming the words to replace the words with corresponsing Glove vectors\n",
    "* Not removing stop words, as some authors whose articles aren't published online may not hesitate to use lot of stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_join(text):\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    text = re.sub('\"([^\"]*)\"', '', text)\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if len(wn.synsets(token)) > 0:\n",
    "            token.strip()\n",
    "            filtered_tokens.append(token)\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['articles_filtered'] = df_train['articles'].apply(tokenize_and_join)\n",
    "df_test['articles_filtered'] = df_test['articles'].apply(tokenize_and_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "max_length = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(df_train['articles_filtered']) + list(df_test['articles_filtered']))\n",
    "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(df_train['articles_filtered']), maxlen=max_length)\n",
    "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(df_test['articles_filtered']), maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_seq = to_categorical(df_train['target'])\n",
    "y_test_seq = to_categorical(df_test['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 50 dimensional Glove vectors\n",
    "file = open('/Users/ajit_samudrala/author_attribution/glove50d.txt', encoding=\"utf8\")  \n",
    "embeddings_index={}\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embeddings = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = embeddings\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((max_features, 50), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in word_index.items(): \n",
    "    if i < max_features:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:  \n",
    "            embedding_matrix[i-1] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 50))\n",
    "model.add(Conv1D(32, 5, activation='relu'))\n",
    "model.add(SpatialDropout1D(0.1))\n",
    "model.add(Conv1D(32, 5, activation='relu'))\n",
    "model.add(SpatialDropout1D(0.1))\n",
    "model.add(Bidirectional(LSTM(32, dropout=0.1, recurrent_dropout=0.1, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(32, dropout=0.1, recurrent_dropout=0.1, return_sequences=True)))\n",
    "model.add(GlobalAvgPool1D())\n",
    "model.add(Dense(50, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 50)          500000    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 32)          8032      \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 32)          5152      \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, None, 64)          16640     \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, None, 64)          24832     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                3250      \n",
      "=================================================================\n",
      "Total params: 557,906\n",
      "Trainable params: 557,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix]) # replacing weights matrix with Glove embeddings\n",
    "\n",
    "model.layers[0].trainable = False # As the training set is small, I will not be training word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "Epoch 1/30\n",
      "2500/2500 [==============================] - 29s 12ms/step - loss: 3.9151 - acc: 0.0188 - val_loss: 3.9109 - val_acc: 0.0200\n",
      "Epoch 2/30\n",
      "2500/2500 [==============================] - 28s 11ms/step - loss: 3.9128 - acc: 0.0124 - val_loss: 3.9088 - val_acc: 0.0256\n",
      "Epoch 3/30\n",
      "2500/2500 [==============================] - 30s 12ms/step - loss: 3.9088 - acc: 0.0260 - val_loss: 3.9060 - val_acc: 0.0348\n",
      "Epoch 4/30\n",
      "2500/2500 [==============================] - 31s 13ms/step - loss: 3.9067 - acc: 0.0228 - val_loss: 3.9027 - val_acc: 0.0384\n",
      "Epoch 5/30\n",
      "2500/2500 [==============================] - 31s 12ms/step - loss: 3.9015 - acc: 0.0328 - val_loss: 3.8972 - val_acc: 0.0368\n",
      "Epoch 6/30\n",
      "2500/2500 [==============================] - 31s 13ms/step - loss: 3.8964 - acc: 0.0380 - val_loss: 3.8908 - val_acc: 0.0368\n",
      "Epoch 7/30\n",
      "2500/2500 [==============================] - 33s 13ms/step - loss: 3.8895 - acc: 0.0380 - val_loss: 3.8833 - val_acc: 0.0372\n",
      "Epoch 8/30\n",
      "2500/2500 [==============================] - 32s 13ms/step - loss: 3.8807 - acc: 0.0308 - val_loss: 3.8760 - val_acc: 0.0372\n",
      "Epoch 9/30\n",
      "2500/2500 [==============================] - 33s 13ms/step - loss: 3.8722 - acc: 0.0388 - val_loss: 3.8695 - val_acc: 0.0396\n",
      "Epoch 10/30\n",
      "2500/2500 [==============================] - 35s 14ms/step - loss: 3.8612 - acc: 0.0452 - val_loss: 3.8641 - val_acc: 0.0376\n",
      "Epoch 11/30\n",
      "2500/2500 [==============================] - 35s 14ms/step - loss: 3.8529 - acc: 0.0396 - val_loss: 3.8579 - val_acc: 0.0432\n",
      "Epoch 12/30\n",
      "2500/2500 [==============================] - 34s 14ms/step - loss: 3.8452 - acc: 0.0388 - val_loss: 3.8524 - val_acc: 0.0428\n",
      "Epoch 13/30\n",
      "2500/2500 [==============================] - 39s 15ms/step - loss: 3.8408 - acc: 0.0432 - val_loss: 3.8502 - val_acc: 0.0448\n",
      "Epoch 14/30\n",
      "2500/2500 [==============================] - 35s 14ms/step - loss: 3.8302 - acc: 0.0460 - val_loss: 3.8415 - val_acc: 0.0524\n",
      "Epoch 15/30\n",
      "2500/2500 [==============================] - 40s 16ms/step - loss: 3.8226 - acc: 0.0504 - val_loss: 3.8352 - val_acc: 0.0524\n",
      "Epoch 16/30\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: 3.8054 - acc: 0.0488 - val_loss: 3.8244 - val_acc: 0.0592\n",
      "Epoch 17/30\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: 3.7999 - acc: 0.0504 - val_loss: 3.8161 - val_acc: 0.0584\n",
      "Epoch 18/30\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3.7776 - acc: 0.0608 - val_loss: 3.8071 - val_acc: 0.0596\n",
      "Epoch 19/30\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 3.7706 - acc: 0.0572 - val_loss: 3.8017 - val_acc: 0.0620\n",
      "Epoch 20/30\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 3.7596 - acc: 0.0544 - val_loss: 3.7894 - val_acc: 0.0656\n",
      "Epoch 21/30\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 3.7564 - acc: 0.0576 - val_loss: 3.7803 - val_acc: 0.0600\n",
      "Epoch 22/30\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 3.7317 - acc: 0.0584 - val_loss: 3.7824 - val_acc: 0.0568\n",
      "Epoch 23/30\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 3.7283 - acc: 0.0628 - val_loss: 3.7686 - val_acc: 0.0560\n",
      "Epoch 24/30\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 3.7197 - acc: 0.0692 - val_loss: 3.7611 - val_acc: 0.0656\n",
      "Epoch 25/30\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 3.6963 - acc: 0.0672 - val_loss: 3.7462 - val_acc: 0.0668\n",
      "Epoch 26/30\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 3.6845 - acc: 0.0684 - val_loss: 3.7306 - val_acc: 0.0668\n",
      "Epoch 27/30\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 3.6666 - acc: 0.0672 - val_loss: 3.7481 - val_acc: 0.0608\n",
      "Epoch 28/30\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 3.6613 - acc: 0.0768 - val_loss: 3.7265 - val_acc: 0.0652\n",
      "Epoch 29/30\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 3.6656 - acc: 0.0696 - val_loss: 3.7171 - val_acc: 0.0660\n",
      "Epoch 30/30\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 3.6399 - acc: 0.0784 - val_loss: 3.7251 - val_acc: 0.0664\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train_seq, y_train_seq, epochs=30, batch_size=512, validation_data=(X_test_seq, y_test_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected accuracy is really bad. Nonetheless, I will try if the network has learned any high level features that may actually improve the accuracy of the earlier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = model.input\n",
    "# capturing the final avg pool layer activations to see if they have captured any imp features\n",
    "out = model.layers[7].output \n",
    "func = K.function([inp, K.learning_phase()], [out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:blue;\">Combining top features obtained from the previous model with the features learned from the network. I am combining with only top features so that model will be forced to chose the add on features learned from netowrk</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = np.concatenate([func([X_train_seq, 0])[0], X_train.toarray()[:, top_features]], axis=1)\n",
    "X_test_combined = np.concatenate([func([X_test_seq, 1])[0], X_test.toarray()[:, top_features]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the original TF-IDF Matrix is (2500, 1787)\n",
      "shape of the TF-IDF matrix combined with features from neural network is (2500, 214)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the original TF-IDF Matrix is {}\".format(X_train.shape))\n",
    "print(\"shape of the TF-IDF matrix combined with features from neural network is {}\".format(X_train_combined.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Red;\"><b><i>Combined Matrix XGBOOST model</i></b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = xgb.DMatrix(X_train_combined, y_train)\n",
    "test_data = xgb.DMatrix(X_test_combined, y_test)\n",
    "watchlist = [(train_data, 'train_score'), (test_data, 'test_score')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'booster': 'gbtree', 'max_depth': 2, 'objective': 'multi:softmax', 'eta': 0.08, 'gamma': 1.5, \n",
    "          'num_class': 50, 'saubsample': 0.7, 'eval_metric': ['merror', 'mlogloss'], 'colsample_bytree': 0.7, 'tree_method': 'exact',\n",
    "          'lambda': 2, 'min_child_weight': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain_score-merror:0.5664\ttrain_score-mlogloss:3.58805\ttest_score-merror:0.6612\ttest_score-mlogloss:3.6415\n",
      "[1]\ttrain_score-merror:0.464\ttrain_score-mlogloss:3.32186\ttest_score-merror:0.6276\ttest_score-mlogloss:3.45052\n",
      "[2]\ttrain_score-merror:0.4112\ttrain_score-mlogloss:3.08747\ttest_score-merror:0.594\ttest_score-mlogloss:3.27983\n",
      "[3]\ttrain_score-merror:0.3672\ttrain_score-mlogloss:2.89336\ttest_score-merror:0.5712\ttest_score-mlogloss:3.14208\n",
      "[4]\ttrain_score-merror:0.3356\ttrain_score-mlogloss:2.72798\ttest_score-merror:0.5556\ttest_score-mlogloss:3.02756\n",
      "[5]\ttrain_score-merror:0.3176\ttrain_score-mlogloss:2.58258\ttest_score-merror:0.5476\ttest_score-mlogloss:2.92\n",
      "[6]\ttrain_score-merror:0.3032\ttrain_score-mlogloss:2.45304\ttest_score-merror:0.5416\ttest_score-mlogloss:2.82772\n",
      "[7]\ttrain_score-merror:0.292\ttrain_score-mlogloss:2.3454\ttest_score-merror:0.5344\ttest_score-mlogloss:2.74996\n",
      "[8]\ttrain_score-merror:0.2808\ttrain_score-mlogloss:2.24306\ttest_score-merror:0.5288\ttest_score-mlogloss:2.67947\n",
      "[9]\ttrain_score-merror:0.2772\ttrain_score-mlogloss:2.1493\ttest_score-merror:0.5288\ttest_score-mlogloss:2.61684\n",
      "[10]\ttrain_score-merror:0.2656\ttrain_score-mlogloss:2.06591\ttest_score-merror:0.5208\ttest_score-mlogloss:2.5567\n",
      "[11]\ttrain_score-merror:0.2636\ttrain_score-mlogloss:1.98952\ttest_score-merror:0.5204\ttest_score-mlogloss:2.5036\n",
      "[12]\ttrain_score-merror:0.2564\ttrain_score-mlogloss:1.91804\ttest_score-merror:0.5216\ttest_score-mlogloss:2.45307\n",
      "[13]\ttrain_score-merror:0.2504\ttrain_score-mlogloss:1.85321\ttest_score-merror:0.5192\ttest_score-mlogloss:2.4062\n",
      "[14]\ttrain_score-merror:0.2436\ttrain_score-mlogloss:1.79366\ttest_score-merror:0.5204\ttest_score-mlogloss:2.36756\n",
      "[15]\ttrain_score-merror:0.2376\ttrain_score-mlogloss:1.73541\ttest_score-merror:0.5132\ttest_score-mlogloss:2.32897\n",
      "[16]\ttrain_score-merror:0.2356\ttrain_score-mlogloss:1.682\ttest_score-merror:0.5112\ttest_score-mlogloss:2.29215\n",
      "[17]\ttrain_score-merror:0.224\ttrain_score-mlogloss:1.63237\ttest_score-merror:0.508\ttest_score-mlogloss:2.25725\n",
      "[18]\ttrain_score-merror:0.2236\ttrain_score-mlogloss:1.58557\ttest_score-merror:0.5104\ttest_score-mlogloss:2.22662\n",
      "[19]\ttrain_score-merror:0.2164\ttrain_score-mlogloss:1.54152\ttest_score-merror:0.5096\ttest_score-mlogloss:2.19605\n",
      "[20]\ttrain_score-merror:0.2132\ttrain_score-mlogloss:1.49928\ttest_score-merror:0.5084\ttest_score-mlogloss:2.16869\n",
      "[21]\ttrain_score-merror:0.21\ttrain_score-mlogloss:1.46051\ttest_score-merror:0.51\ttest_score-mlogloss:2.14393\n",
      "[22]\ttrain_score-merror:0.2088\ttrain_score-mlogloss:1.42238\ttest_score-merror:0.5092\ttest_score-mlogloss:2.11964\n",
      "[23]\ttrain_score-merror:0.2064\ttrain_score-mlogloss:1.38644\ttest_score-merror:0.5088\ttest_score-mlogloss:2.09759\n",
      "[24]\ttrain_score-merror:0.1976\ttrain_score-mlogloss:1.35192\ttest_score-merror:0.506\ttest_score-mlogloss:2.07471\n",
      "[25]\ttrain_score-merror:0.1928\ttrain_score-mlogloss:1.3197\ttest_score-merror:0.5032\ttest_score-mlogloss:2.05308\n",
      "[26]\ttrain_score-merror:0.1892\ttrain_score-mlogloss:1.28922\ttest_score-merror:0.5012\ttest_score-mlogloss:2.036\n",
      "[27]\ttrain_score-merror:0.1844\ttrain_score-mlogloss:1.25973\ttest_score-merror:0.5016\ttest_score-mlogloss:2.0186\n",
      "[28]\ttrain_score-merror:0.1824\ttrain_score-mlogloss:1.23246\ttest_score-merror:0.5\ttest_score-mlogloss:1.99968\n",
      "[29]\ttrain_score-merror:0.1812\ttrain_score-mlogloss:1.20512\ttest_score-merror:0.5008\ttest_score-mlogloss:1.98309\n",
      "[30]\ttrain_score-merror:0.1764\ttrain_score-mlogloss:1.17809\ttest_score-merror:0.496\ttest_score-mlogloss:1.967\n",
      "[31]\ttrain_score-merror:0.1752\ttrain_score-mlogloss:1.15356\ttest_score-merror:0.4964\ttest_score-mlogloss:1.95097\n",
      "[32]\ttrain_score-merror:0.1696\ttrain_score-mlogloss:1.12905\ttest_score-merror:0.4984\ttest_score-mlogloss:1.93741\n",
      "[33]\ttrain_score-merror:0.166\ttrain_score-mlogloss:1.10626\ttest_score-merror:0.4992\ttest_score-mlogloss:1.92196\n",
      "[34]\ttrain_score-merror:0.162\ttrain_score-mlogloss:1.08464\ttest_score-merror:0.4916\ttest_score-mlogloss:1.90931\n",
      "[35]\ttrain_score-merror:0.1612\ttrain_score-mlogloss:1.06386\ttest_score-merror:0.4904\ttest_score-mlogloss:1.89691\n",
      "[36]\ttrain_score-merror:0.1568\ttrain_score-mlogloss:1.04271\ttest_score-merror:0.4912\ttest_score-mlogloss:1.88537\n",
      "[37]\ttrain_score-merror:0.1544\ttrain_score-mlogloss:1.02291\ttest_score-merror:0.4928\ttest_score-mlogloss:1.87348\n",
      "[38]\ttrain_score-merror:0.152\ttrain_score-mlogloss:1.0041\ttest_score-merror:0.4916\ttest_score-mlogloss:1.86319\n",
      "[39]\ttrain_score-merror:0.1484\ttrain_score-mlogloss:0.98577\ttest_score-merror:0.4868\ttest_score-mlogloss:1.85116\n",
      "[40]\ttrain_score-merror:0.1464\ttrain_score-mlogloss:0.967678\ttest_score-merror:0.4872\ttest_score-mlogloss:1.84221\n",
      "[41]\ttrain_score-merror:0.144\ttrain_score-mlogloss:0.949521\ttest_score-merror:0.4868\ttest_score-mlogloss:1.83295\n",
      "[42]\ttrain_score-merror:0.1428\ttrain_score-mlogloss:0.932248\ttest_score-merror:0.4848\ttest_score-mlogloss:1.82306\n",
      "[43]\ttrain_score-merror:0.1392\ttrain_score-mlogloss:0.916267\ttest_score-merror:0.4844\ttest_score-mlogloss:1.81432\n",
      "[44]\ttrain_score-merror:0.1368\ttrain_score-mlogloss:0.900338\ttest_score-merror:0.4828\ttest_score-mlogloss:1.80501\n",
      "[45]\ttrain_score-merror:0.1344\ttrain_score-mlogloss:0.88483\ttest_score-merror:0.4792\ttest_score-mlogloss:1.79773\n",
      "[46]\ttrain_score-merror:0.1336\ttrain_score-mlogloss:0.869997\ttest_score-merror:0.4796\ttest_score-mlogloss:1.79091\n",
      "[47]\ttrain_score-merror:0.1312\ttrain_score-mlogloss:0.855271\ttest_score-merror:0.4816\ttest_score-mlogloss:1.78216\n",
      "[48]\ttrain_score-merror:0.1284\ttrain_score-mlogloss:0.841304\ttest_score-merror:0.4824\ttest_score-mlogloss:1.77402\n",
      "[49]\ttrain_score-merror:0.1268\ttrain_score-mlogloss:0.826767\ttest_score-merror:0.4796\ttest_score-mlogloss:1.76502\n",
      "[50]\ttrain_score-merror:0.126\ttrain_score-mlogloss:0.813773\ttest_score-merror:0.478\ttest_score-mlogloss:1.75806\n",
      "[51]\ttrain_score-merror:0.1228\ttrain_score-mlogloss:0.800687\ttest_score-merror:0.476\ttest_score-mlogloss:1.75135\n",
      "[52]\ttrain_score-merror:0.1208\ttrain_score-mlogloss:0.788686\ttest_score-merror:0.4788\ttest_score-mlogloss:1.7456\n",
      "Stopping. Best iteration:\n",
      "[49]\ttrain_score-merror:0.068\ttrain_score-mlogloss:0.720622\ttest_score-merror:0.4368\ttest_score-mlogloss:1.68475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_xgb_comb = xgb.train(params, train_data, evals=watchlist, num_boost_round=60, callbacks=[xgb_early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = clf_xgb_comb.predict(train_data)\n",
    "pred_test = clf_xgb_comb.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGboost model on the TF-IDF train matrix combined with features from neural netowrk is 0.88\n",
      "Accuracy of XGboost model on the TF-IDF test matrix combined with features from neural netowrk is 0.524\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of XGboost model on the TF-IDF train matrix combined with features from neural netowrk is {}\".format(\n",
    "    metrics.accuracy_score(pred_train, y_train)))\n",
    "print(\"Accuracy of XGboost model on the TF-IDF test matrix combined with features from neural netowrk is {}\".format(\n",
    "    metrics.accuracy_score(pred_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even this strategy didn't work out and still BernoulliNB tops the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Red;\"><b><i>Manual Error Analysis</i></b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the best performing model is BernoulliNB , I will do error analysis on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = clf_nb.predict(X_test)\n",
    "mis_cls_samples = np.where(pred_test != y_test)[0]\n",
    "report = metrics.classification_report(y_pred=pred_test, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_to_df(report):\n",
    "    report = re.sub(r\" +\", \" \", report).replace(\"avg / total\", \"avg/total\").replace(\"\\n \", \"\\n\")\n",
    "    report_df = pd.read_csv(StringIO(\"Classes\" + report), sep=' ', index_col=0)\n",
    "    return (report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = report_to_df(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_recall_scores = result_df.loc[result_df['recall']<0.5,:].sort_values('recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.21</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.35</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.33</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.45</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.59</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.36</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.58</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.40</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         precision  recall  f1-score  support\n",
       "Classes                                      \n",
       "7             0.39    0.14      0.21       50\n",
       "6             0.86    0.24      0.38       50\n",
       "14            0.36    0.26      0.30       50\n",
       "34            0.54    0.26      0.35       50\n",
       "12            0.31    0.34      0.33       50\n",
       "18            0.53    0.40      0.45       50\n",
       "8             0.62    0.42      0.50       50\n",
       "31            1.00    0.42      0.59       50\n",
       "43            0.29    0.42      0.34       50\n",
       "49            0.31    0.42      0.36       50\n",
       "2             0.85    0.44      0.58       50\n",
       "48            0.37    0.44      0.40       50\n",
       "23            0.57    0.48      0.52       50"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_recall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19e2a9c5a20>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=bad_recall_scores.index, y=bad_recall_scores['recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table class 7 is the most misclassified class. I will try to see what are its predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5,  7, 12, 20, 22, 36, 39, 48], dtype=int64),\n",
       " array([ 6,  7,  1,  2,  6,  2,  2, 24], dtype=int64))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred_test[7 * 50 - 1: 7 * 50 + 49], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class 7 is often mislabeled as class 48. We can furthur investigate to se why these are being mislabeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Red;\"><b><i>Future Work</i></b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform extensive parameter tuning starting from the choice of whether using stemming or lemmatization to parameters of the model.\n",
    "* Try different neural network architectures to better capture author writing style. For example, article level based architecture instead of sentence-level architecture\n",
    "* Try using POS tagging to see if any author tend to use certain POS more in their articles\n",
    "* If possible gain more data or allocate more data to the training data to get a better representation of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
